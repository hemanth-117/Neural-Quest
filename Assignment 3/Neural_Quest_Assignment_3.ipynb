{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xwo8D8V-uPsI"
   },
   "source": [
    "# Neural Quest Assignment-3\n",
    "<center>\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS7fZ0PJ4leQi4qtXR5Egv5YILqQqvzVSNtFg&usqp=CAU\">\n",
    "</center>\n",
    "\n",
    "*  In this assignment, we will use CNNs in [PyTorch](https://pytorch.org/docs/stable/index.html) for image classification.\n",
    "\n",
    "* We have been using MNIST by flattening 28$\\times$28 images to 784-sized vectors.\n",
    "\n",
    "* This time, we will classify images from the CIFAR-10 dataset - dimension is 32$\\times$32.\n",
    "\n",
    "* Much of this notebook remains the same as for Assignment 2, just minor changes would be needed and this assignment won't take long.\n",
    "\n",
    "**Feel free to redefine any function signatures below, just make sure the final cell remains the same.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQNvtQCE_j1Q"
   },
   "source": [
    "## Import libraries here\n",
    "PyTorch, NumPy, Matplotlib, ...\n",
    "Even when equipped with PyTorch, NumPy and Matplotlib make your work easier for visualization etc.\n",
    "\n",
    "Note the following method to **initialize the seed** for reproducibility of results, both for NumPy & PyTorch (CPU/CUDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnnyxVTxqpZB"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    # np.random.seed(seed)\n",
    "    # torch.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed(seed)\n",
    "    # # When running on the CuDNN backend, two further options must be set\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "    # # Set a fixed value for the hash seed\n",
    "    # os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6dAe4V0_3zC"
   },
   "source": [
    "## Load *Dataset*\n",
    "Use the [pickle file](https://drive.google.com/file/d/1W4T7PdA2lJ3XLAOckKOs7lPnuDhS2Jez/view?usp=sharing) shared for this assignment here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umr8-1EI_3ez"
   },
   "outputs": [],
   "source": [
    "# load the data set\n",
    "\n",
    "X = pass\n",
    "y = pass\n",
    "\n",
    "\n",
    "# Split into X_train, y_train, X_test, y_test\n",
    "# you can use stratified splitting from sklearn library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4174DiUAUIJ"
   },
   "outputs": [],
   "source": [
    "# display a 4x4 grid, \n",
    "# choose 16 images randomly, display the images as well as corresponding labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjY5oNGRAK1e"
   },
   "source": [
    "## Creating a Dataset Class\n",
    "In PyTorch, there is existing implementation of batch-splitting. You don't need to do it manually over here. Instead, just define a Dataset class and a Dataloader wrapping it.\n",
    "\n",
    "A dataset class must have 3 functions - ```__init__```, ```__len__```, ```__getitem__```. Their names are pretty self-explanatory. You can read more about this [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html).\n",
    "\n",
    "You will have to perform normalization, augmentation on the dataset here itself, have a look at [PyTorch Transforms](https://pytorch.org/vision/stable/transforms.html).\n",
    "\n",
    "**Note -** While initializing the dataset class object, make sure you only pass the numpy arrays for images and labels. So the ```__init__``` function should look like\n",
    "```\n",
    "    def __init__(self, X, y):\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vifSrimqBGjH"
   },
   "outputs": [],
   "source": [
    "# define your dataset class\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOs6uifpBF8P"
   },
   "source": [
    "## ```nn.Module``` for your model\n",
    "In this segment, define a class for your model, it has to inherit from the ```nn.Module``` class. You must define two functions here - ```__init__``` and ```forward```, again pretty self-explanatory. Helper functions can also be implemented, your choice!\n",
    "\n",
    "Look into the following ```torch``` layers beyond those you used in the second assignment and combine them to form your network, you can find more [here](https://pytorch.org/docs/stable/nn.html) -\n",
    "- [```nn.Conv2d```](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "- [```nn.BatchNorm2d```](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Mr6_5pzGRjp"
   },
   "outputs": [],
   "source": [
    "# define a child class of nn.Module for your model\n",
    "# specify the architecture here itself\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVTyirdELXlt"
   },
   "source": [
    "## Training loop\n",
    "You can write a training loop but usually writing it within a function helps so that you can train in multiple passes with just one function call if you still don't see convergence of the loss. ```display_step``` is for you to display results on the validation set (which you must not have trained upon).\n",
    "\n",
    "You will need to use ```zero_grad()```, ```backward()``` and multiple such functions here. Look for them in the tutorials given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0BnrNm8LN5s"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, display_step=None):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g319ipPXMh0R"
   },
   "source": [
    "## Initialize weights\n",
    "Write a small function to initialize weights for your model. You don't need to do it individually for each layer, there are ways to do it in a simple ```for``` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRqqKNLZMjDe"
   },
   "outputs": [],
   "source": [
    "def init_weights(...):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivuHRGtfN3sE"
   },
   "source": [
    "## Prediction & Accuracy\n",
    "Prediction function should predict outputs using your trained model for a given **NumPy array** ```X_test``` and the output should be another **NumPy array**.\n",
    "\n",
    "The accuracy function would be the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPX1q_0AN3ZV"
   },
   "outputs": [],
   "source": [
    "def predict(model, X_test):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nKROVpWOa6j"
   },
   "outputs": [],
   "source": [
    "def accuracy(pred, labels):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aA1EWZmMbQe"
   },
   "source": [
    "## Actually training your model\n",
    "- Create a model, initialize it. Define optimizer for the model as well as loss criterion (you can actually set the seed here again, just in case you did some ```rand``` calls above for testing your functions).\n",
    "- Define an instance of the dataset class, wrap it in a dataloader.\n",
    "- Call the train function and train your model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8JG_XURNLmr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQsiK0-COe6E"
   },
   "source": [
    "## Run your model for the validation dataset\n",
    "Use your trained model to get predictions for the validation dataset you split earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_B_NUjUOq3c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f4W_facj-PA"
   },
   "source": [
    "## Submission\n",
    "To submit your solution, you will need to make a file with name ```model.py``` containing imports necessary to write the model class and the model class itself. It shouldn't do anything else when run. Also create a file ```dataset.py``` with the dataset class and all necessary imports. Other than this, save the trained model in a file named ```ass_2.pt```. When you are done with the assignment, commit the updated notebook, the ```model.py```, ```dataset.py``` class files and the ```ass_2.pt``` model-weights file to the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7tknYAy1j92M"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "torch.save(final_model, 'ass_2.pt')\n",
    "files.download('ass_2.pt') # download the file from the Colab session for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flMRBW9Akhkg"
   },
   "source": [
    "Check if it got saved right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wA9nHzYkj1R"
   },
   "outputs": [],
   "source": [
    "# load the model, use predict function\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN-lytical Assignment-3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
