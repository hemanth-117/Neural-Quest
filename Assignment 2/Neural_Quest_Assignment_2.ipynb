{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-lytical Assignment-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN-lytical Assignment-2\n",
        "<center>\n",
        "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS7fZ0PJ4leQi4qtXR5Egv5YILqQqvzVSNtFg&usqp=CAU\">\n",
        "</center>\n",
        "\n",
        "*  In this assignment, we will build a classifier for MNIST from using [PyTorch](https://pytorch.org/docs/stable/index.html). \n",
        "\n",
        "*   We will be using the same dataset as the previous assignment for MNIST. **Do not** use the complete MNIST dataset, even though PyTorch makes it really easy.\n",
        "\n",
        "*   No limitations on your model this time, just don't use CNNs now, that's up next week.\n",
        "\n",
        "**Feel free to redefine any function signatures below, just make sure the final cell remains the same.**"
      ],
      "metadata": {
        "id": "Xwo8D8V-uPsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries here\n",
        "PyTorch, NumPy, Matplotlib, ...\n",
        "Even when equipped with PyTorch, NumPy and Matplotlib make your work easier for visualization etc.\n",
        "\n",
        "Also remember to **initialize the seed** for reproducibility of results, both for NumPy & PyTorch."
      ],
      "metadata": {
        "id": "QQNvtQCE_j1Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnnyxVTxqpZB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load *Dataset*\n",
        "Use the pickle file shared for the previous assignment here."
      ],
      "metadata": {
        "id": "D6dAe4V0_3zC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data set\n",
        "\n",
        "X = pass\n",
        "y = pass\n",
        "\n",
        "# normalize the dataset, won't be doing it here in later assignments\n",
        "\n",
        "\n",
        "\n",
        "# Split into X_train, y_train, X_test, y_test\n",
        "# you can use stratified splitting from sklearn library\n",
        "\n"
      ],
      "metadata": {
        "id": "umr8-1EI_3ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display a 4x4 grid, \n",
        "# choose 16 images randomly, display the images as well as corresponding labels\n"
      ],
      "metadata": {
        "id": "w4174DiUAUIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Dataset Class\n",
        "In PyTorch, there is existing implementation of batch-splitting. You don't need to do it manually over here. Instead, just define a Dataset class and a Dataloader wrapping it.\n",
        "\n",
        "A dataset class must have 3 functions - ```__init__```, ```__len__```, ```__getitem__```. Their names are pretty self-explanatory. You can read more about this [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html).\n",
        "\n",
        "\n",
        "**Note** - Things like normalization, augmentation etc. which are related to the dataset are all done in this class. However, because this assignment doesn't deal with MNIST images but rather feature vectors, this part is being skipped here and will be discussed in Assignment 3."
      ],
      "metadata": {
        "id": "ZjY5oNGRAK1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define your dataset class\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vifSrimqBGjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ```nn.Module``` for your model\n",
        "In this segment, define a class for your model, it has to inherit from the ```nn.Module``` class. You must define two functions here - ```__init__``` and ```forward```, again pretty self-explanatory. Helper functions can also be implemented, your choice!\n",
        "\n",
        "Look into the following ```torch``` layers and combine them to form your network, you can find more [here](https://pytorch.org/docs/stable/nn.html) -\n",
        "- [```nn.Linear```](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
        "- [```nn.ReLU```](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n",
        "- [```nn.BatchNorm1d```](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html)\n"
      ],
      "metadata": {
        "id": "DOs6uifpBF8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a child class of nn.Module for your model\n",
        "# specify the architecture here itself\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6Mr6_5pzGRjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop\n",
        "You can write a training loop but usually writing it within a function helps so that you can train in multiple passes with just one function call if you still don't see convergence of the loss. ```display_step``` is for you to display results on the validation set (which you must not have trained upon).\n",
        "\n",
        "You will need to use ```zero_grad()```, ```backward()``` and multiple such functions here. Look for them in the tutorials given."
      ],
      "metadata": {
        "id": "tVTyirdELXlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion, train_loader, display_step=None):\n",
        "    pass"
      ],
      "metadata": {
        "id": "z0BnrNm8LN5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize weights\n",
        "Write a small function to initialize weights for your model. You don't need to do it individually for each layer, there are ways to do it in a simple ```for``` loop."
      ],
      "metadata": {
        "id": "g319ipPXMh0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(...):\n",
        "    pass"
      ],
      "metadata": {
        "id": "GRqqKNLZMjDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction & Accuracy\n",
        "Prediction function should predict outputs using your trained model for a given **NumPy array** ```X_test``` and the output should be another **NumPy array**.\n",
        "\n",
        "The accuracy function would be the same as before."
      ],
      "metadata": {
        "id": "ivuHRGtfN3sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, X_test):\n",
        "    pass"
      ],
      "metadata": {
        "id": "cPX1q_0AN3ZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(pred, labels):\n",
        "    pass"
      ],
      "metadata": {
        "id": "_nKROVpWOa6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actually training your model\n",
        "- Create a model, initialize it. Define optimizer for the model as well as loss criterion (you can actually set the seed here again, just in case you did some ```rand``` calls above for testing your functions).\n",
        "- Define an instance of the dataset class, wrap it in a dataloader.\n",
        "- Call the train function and train your model!\n"
      ],
      "metadata": {
        "id": "8aA1EWZmMbQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F8JG_XURNLmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run your model for the validation dataset\n",
        "Use your trained model to get predictions for the validation dataset you split earlier."
      ],
      "metadata": {
        "id": "OQsiK0-COe6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "i_B_NUjUOq3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission\n",
        "To submit your solution, you will need to make a file with name ```model.py``` containing imports necessary to write the model class and the model class itself. It shouldn't do anything else when run. Other than this, save the trained model in a file named ```ass_2.pt```. When you are done with the assignment, commit the updated notebook, the ```model.py``` class file and the ```ass_2.pt``` model-weights file to the repository."
      ],
      "metadata": {
        "id": "0f4W_facj-PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "torch.save(final_model, 'ass_2.pt')\n",
        "files.download('ass_2.pt') # download the file from the Colab session for submission"
      ],
      "metadata": {
        "id": "7tknYAy1j92M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if it got saved right!"
      ],
      "metadata": {
        "id": "flMRBW9Akhkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model, use predict function\n"
      ],
      "metadata": {
        "id": "-wA9nHzYkj1R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}